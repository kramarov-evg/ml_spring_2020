
1st lab:
  1st subtask:
    [x] Read data @done(20-05-15 10:24)
    [x] Translate into floats @done(20-05-15 10:25)
    [x] Separate labels from features @done(20-05-15 10:26)
    [x] Try test/train split @started(20-05-15 10:58) @done(20-05-15 11:10) @lasted(12m9s)
    [x] Loop over test/train ratios @started(20-05-15 11:10) @done(20-05-15 11:27) @lasted(17m5s)
    [x] Refactor (logic to functions) @started(20-05-21 01:53) @done(20-05-21 02:55) @lasted(1h2m53s)
    [x] Plot results @done(20-05-21 02:55)
    [ ] Report on results
  2nd subtask:
    [x] Generate points @done(20-05-22 03:34)
    [x] Plot points @done(20-05-22 03:41)
    [ ] Adjust plot size @beautify
    [x] Create & train classifier @started(20-05-22 04:09) @done(20-05-22 04:37) @lasted(28m48s)
    [x] Get accuracy @done(20-05-22 04:48)
    [x] Confusion matrix @done(20-05-22 04:48)
    [x] ROC-curve @done(20-05-22 04:48)
    [x] PR-curve @done(20-05-22 04:48)
    [x] Plot data @done(20-05-22 04:48)
    [ ] Reimplement with splitting data
    [ ] Report on results
  3rd subtask:
    [x] Load data @started(20-05-22 10:15) @done(20-05-22 10:25) @lasted(10m13s)
    [x] Clean-up data @done(20-05-22 10:29)
    [x] Build classifier @started(20-05-22 11:47) @done(20-05-22 11:52) @lasted(5m44s)
    [x] Loop over neighbours count @started(20-05-22 11:52) @done(20-05-22 12:10) @lasted(18m45s)
    [x] Plot results @done(20-05-22 12:10)
    [x] Explore distance metrics @done(20-05-23 11:10)
    [x] Plot results @done(20-05-23 11:10)
    [x] Classify sample @done(20-05-23 11:10)
    [ ] Report on results
  4th subtask:
    [x] Read on SVM @done(20-05-23 18:40)
    [x] Load data @done(20-05-23 18:40)
    [x] Clean-up data @done(20-05-23 18:40)
    [x] Build classifier with linear kernel @done(20-05-23 18:40)
    [x] Train classifier & plot space division @done(20-05-23 18:41)
    [x] Plot confusion matrix (train + test) & print vectors number @done(20-05-23 18:41)
    [x] Change fine value to 0 error on training and test sets @done(20-05-23 18:41)
    [ ] Beautify @beautify
    4.e Overfitting happens only with rbf (gaussian) and is more visible on higher gamma values
    [ ] Unify 4.e
    [ ] Report on results
  5th subtask:
    [x] Load data @done(20-05-23 22:19)
    [x] Build base tree @done(20-05-23 22:50)
    [x] Visualize tree @done(20-05-23 22:50)
    [ ] Interpret results
    [ ] Decide whether tree is excessive
    [x] Experiment with params and test accuracy with them @done(20-05-24 01:06)
    [x] Load data @done(20-05-24 01:11)
    [x] Build optimal tree @done(20-05-24 01:42)
    [ ] Explain why is optimal
    Because not too big & good accuracy
    [x] Visualize tree @done(20-05-24 01:42)
    [x] Identify most important features @done(20-05-24 01:43)
    Most important is x1, second most is x0
    [x] Estimate classification accuracy @done(20-05-24 01:43)
  6th subtask:
    [x] Load data @done(20-05-24 02:23)
    [x] Create 2 classifiers @done(20-05-24 02:24)
    [x] Train them @done(20-05-24 02:24)
    [x] Select metrics @done(20-05-24 02:24)
    [x] Plot results @done(20-05-24 02:24)

2nd lab:
  1st subtask:
    [x] Create neural network of a single neuron @done(20-05-26 02:46)
    [x] Train & evaluate on nn_0.csv & nn_1.csv. Explain why results differ @done(20-05-26 03:58)
    [x] How many epochs needed? @done(20-05-26 18:52)
    50 is enough
    [x] Experiment with activation functions and optimizers @done(20-05-26 18:52)
  2nd subtask:
    [x] Modify NN from 1st task to fit optimally to nn_1.csv. @done(20-05-26 18:52)
    [x] What changed? Why? @done(20-05-26 18:52)
  3rd subtask:
    [x] Build classifier for MNIST dataset & evaluate classification quality @done(20-05-26 18:52)

3rd lab:
  1st subtask:
    [ ] Divide into 3 clusters pluton.csv with k-means
    [ ] Compare division quality dependent on number of iterations, algorithm and standartization
    [ ] Clusterize datasets with k-means, DBSCAN & ierarchical
    [ ] Choose optimal number of clusters (where aplicable)
    [ ] Which method performed better?
    [ ] Get n clusters of image colors
    [ ] Get their centers
    [ ] Compress colorspace
    [ ] Compare original & compressed image
    [ ] Build dendrogram for votes.csv
    [ ] Interpret results
